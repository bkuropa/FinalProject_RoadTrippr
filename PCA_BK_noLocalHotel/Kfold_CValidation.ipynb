{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965b6fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43817517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d76408d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bkuro\\AppData\\Local\\Temp\\ipykernel_55720\\3934716007.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df = df.drop('Clusters5', 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>churches</th>\n",
       "      <th>resorts</th>\n",
       "      <th>beaches</th>\n",
       "      <th>parks</th>\n",
       "      <th>theatres</th>\n",
       "      <th>museums</th>\n",
       "      <th>malls</th>\n",
       "      <th>zoo</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>pubs-bars</th>\n",
       "      <th>...</th>\n",
       "      <th>dance-clubs</th>\n",
       "      <th>swimming-pools</th>\n",
       "      <th>gyms</th>\n",
       "      <th>bakeries</th>\n",
       "      <th>beauty-spas</th>\n",
       "      <th>cafes</th>\n",
       "      <th>view-points</th>\n",
       "      <th>monuments</th>\n",
       "      <th>gardens</th>\n",
       "      <th>Clusters4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User 1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.65</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.65</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.63</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.63</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.63</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         churches  resorts  beaches  parks  theatres  museums  malls   zoo  \\\n",
       "user_id                                                                      \n",
       "User 1        0.0      0.0     3.63   3.65       5.0     2.92    5.0  2.35   \n",
       "User 2        0.0      0.0     3.63   3.65       5.0     2.92    5.0  2.64   \n",
       "User 3        0.0      0.0     3.63   3.63       5.0     2.92    5.0  2.64   \n",
       "User 4        0.0      0.5     3.63   3.63       5.0     2.92    5.0  2.35   \n",
       "User 5        0.0      0.0     3.63   3.63       5.0     2.92    5.0  2.64   \n",
       "\n",
       "         restaurants  pubs-bars  ...  dance-clubs  swimming-pools  gyms  \\\n",
       "user_id                          ...                                      \n",
       "User 1          2.33       2.64  ...         0.59             0.5   0.0   \n",
       "User 2          2.33       2.65  ...         0.59             0.5   0.0   \n",
       "User 3          2.33       2.64  ...         0.59             0.5   0.0   \n",
       "User 4          2.33       2.64  ...         0.59             0.5   0.0   \n",
       "User 5          2.33       2.64  ...         0.59             0.5   0.0   \n",
       "\n",
       "         bakeries  beauty-spas  cafes  view-points  monuments  gardens  \\\n",
       "user_id                                                                  \n",
       "User 1        0.5          0.0    0.0          0.0        0.0      0.0   \n",
       "User 2        0.5          0.0    0.0          0.0        0.0      0.0   \n",
       "User 3        0.5          0.0    0.0          0.0        0.0      0.0   \n",
       "User 4        0.5          0.0    0.0          0.0        0.0      0.0   \n",
       "User 5        0.5          0.0    0.0          0.0        0.0      0.0   \n",
       "\n",
       "         Clusters4  \n",
       "user_id             \n",
       "User 1           1  \n",
       "User 2           1  \n",
       "User 3           1  \n",
       "User 4           1  \n",
       "User 5           1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('clustered_gd_noLSH.csv',header=0,index_col=False) \n",
    "df = df.set_index('user_id')\n",
    "df = df.drop('Clusters5', 1)\n",
    "df.head()\n",
    "#df = pd.DataFrame(X, columns=['f{}'.format(i) for i in range(8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee902de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(columns=[\"Clusters4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3afbc004",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Clusters4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1f47e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3ecad10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.25, random_state=90210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "929401f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to divide the df by cluster, we need to ensure we use the correct class labels, we'll use pandas to do that\n",
    "train_clusters = X_train.copy()\n",
    "test_clusters = X_test.copy()\n",
    "train_clusters['y'] = y_train\n",
    "test_clusters['y'] = y_test\n",
    "\n",
    "\n",
    "# locate the \"0\" cluster\n",
    "train_0 = train_clusters.loc[train_clusters.Clusters4 == 0] \n",
    "test_0 = test_clusters.loc[test_clusters.Clusters4 == 0]\n",
    "y_train_0 = train_0.y.values\n",
    "y_test_0 = test_0.y.values\n",
    "# locate the \"1\" cluster\n",
    "train_1 = train_clusters.loc[train_clusters.Clusters4 == 1] \n",
    "test_1 = test_clusters.loc[test_clusters.Clusters4 == 1]\n",
    "y_train_1 = train_1.y.values\n",
    "y_test_1 = test_1.y.values\n",
    "# locate the \"2\" cluster\n",
    "train_2 = train_clusters.loc[train_clusters.Clusters4 == 2] \n",
    "test_2 = test_clusters.loc[test_clusters.Clusters4 == 2]\n",
    "y_train_2 = train_2.y.values\n",
    "y_test_2 = test_2.y.values\n",
    "# locate the \"3\" cluster\n",
    "train_3 = train_clusters.loc[train_clusters.Clusters4 == 3] \n",
    "test_3 = test_clusters.loc[test_clusters.Clusters4 == 3]\n",
    "y_train_3 = train_3.y.values\n",
    "y_test_3 = test_3.y.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a3c177a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>churches</th>\n",
       "      <th>resorts</th>\n",
       "      <th>beaches</th>\n",
       "      <th>parks</th>\n",
       "      <th>theatres</th>\n",
       "      <th>museums</th>\n",
       "      <th>malls</th>\n",
       "      <th>zoo</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>pubs-bars</th>\n",
       "      <th>...</th>\n",
       "      <th>swimming-pools</th>\n",
       "      <th>gyms</th>\n",
       "      <th>bakeries</th>\n",
       "      <th>beauty-spas</th>\n",
       "      <th>cafes</th>\n",
       "      <th>view-points</th>\n",
       "      <th>monuments</th>\n",
       "      <th>gardens</th>\n",
       "      <th>Clusters4</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User 3468</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.66</td>\n",
       "      <td>3.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 2480</th>\n",
       "      <td>0.79</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.64</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 4388</th>\n",
       "      <td>1.47</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.92</td>\n",
       "      <td>2.49</td>\n",
       "      <td>2.28</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.46</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.45</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 1659</th>\n",
       "      <td>1.50</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.94</td>\n",
       "      <td>2.05</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2.23</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1.49</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 4290</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.46</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.49</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.32</td>\n",
       "      <td>...</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.59</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 2527</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.55</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.59</td>\n",
       "      <td>2.44</td>\n",
       "      <td>3.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 1931</th>\n",
       "      <td>0.72</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.45</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.13</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.74</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 679</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.48</td>\n",
       "      <td>2.71</td>\n",
       "      <td>2.73</td>\n",
       "      <td>...</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 4911</th>\n",
       "      <td>1.14</td>\n",
       "      <td>1.32</td>\n",
       "      <td>2.64</td>\n",
       "      <td>2.64</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.79</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.12</td>\n",
       "      <td>3.11</td>\n",
       "      <td>2.57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.06</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 142</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.38</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.41</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.66</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           churches  resorts  beaches  parks  theatres  museums  malls   zoo  \\\n",
       "user_id                                                                        \n",
       "User 3468      0.00     0.00     1.48   1.41      1.40     1.41   1.42  1.45   \n",
       "User 2480      0.79     1.42     1.40   1.39      1.41     1.61   1.45  2.64   \n",
       "User 4388      1.47     1.65     2.46   1.89      1.88     1.88   1.91  1.92   \n",
       "User 1659      1.50     1.63     1.99   1.95      1.94     2.05   5.00  2.12   \n",
       "User 4290      0.00     1.46     1.44   1.43      1.44     1.49   1.49  2.70   \n",
       "...             ...      ...      ...    ...       ...      ...    ...   ...   \n",
       "User 2527      0.76     0.79     1.57   1.55      1.54     1.55   5.00  1.59   \n",
       "User 1931      0.72     5.00     1.37   1.38      1.44     1.45   5.00  4.13   \n",
       "User 679       0.00     0.00     1.48   1.43      1.42     1.44   1.48  1.48   \n",
       "User 4911      1.14     1.32     2.64   2.64      2.75     2.79   5.00  3.12   \n",
       "User 142       0.78     0.72     1.27   1.29      1.36     1.38   5.00  1.41   \n",
       "\n",
       "           restaurants  pubs-bars  ...  swimming-pools  gyms  bakeries  \\\n",
       "user_id                            ...                                   \n",
       "User 3468         2.66       3.28  ...            0.84  0.86      1.04   \n",
       "User 2480         3.30       3.27  ...            0.86  1.04      1.06   \n",
       "User 4388         2.49       2.28  ...            5.00  0.00      0.00   \n",
       "User 1659         2.62       2.23  ...            5.00  0.00      0.00   \n",
       "User 4290         3.33       3.32  ...            1.01  1.00      1.02   \n",
       "...                ...        ...  ...             ...   ...       ...   \n",
       "User 2527         2.44       3.03  ...            0.70  0.71      0.73   \n",
       "User 1931         5.00       5.00  ...            0.66  0.67      0.70   \n",
       "User 679          2.71       2.73  ...            0.78  0.80      0.92   \n",
       "User 4911         3.11       2.57  ...            0.67  0.67      0.69   \n",
       "User 142          5.00       5.00  ...            0.75  0.75      0.85   \n",
       "\n",
       "           beauty-spas  cafes  view-points  monuments  gardens  Clusters4  y  \n",
       "user_id                                                                       \n",
       "User 3468         1.11   0.00         0.00       0.00     0.00          3  3  \n",
       "User 2480         0.54   0.00         0.00       0.00     0.00          3  3  \n",
       "User 4388         0.61   1.48         1.46       1.45     1.45          3  3  \n",
       "User 1659         0.58   1.50         1.49       1.47     1.49          3  3  \n",
       "User 4290         0.00   0.00         0.00       0.00     1.59          3  3  \n",
       "...                ...    ...          ...        ...      ...        ... ..  \n",
       "User 2527         0.75   0.76         0.75       0.74     0.74          3  3  \n",
       "User 1931         0.72   0.73         0.72       0.70     0.74          3  3  \n",
       "User 679          0.00   0.00         0.00       0.00     0.00          3  3  \n",
       "User 4911         0.00   0.00         1.03       1.04     1.06          3  3  \n",
       "User 142          0.80   0.68         0.66       0.65     0.66          3  3  \n",
       "\n",
       "[333 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37c0d8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the base dataset has no \"clusters\" feature\n",
    "X_train_base = X_train.drop(columns=['Clusters4'])\n",
    "X_test_base = X_test.drop(columns=['Clusters4'])\n",
    "# drop the targets from the training set\n",
    "X_train_0 = train_0.drop(columns=['y'])\n",
    "X_test_0 = test_0.drop(columns=['y'])\n",
    "X_train_1 = train_1.drop(columns=['y'])\n",
    "X_test_1 = test_1.drop(columns=['y'])\n",
    "X_train_2 = train_2.drop(columns=['y'])\n",
    "X_test_2 = test_2.drop(columns=['y'])\n",
    "X_train_3 = train_3.drop(columns=['y'])\n",
    "X_test_3 = test_3.drop(columns=['y'])\n",
    "datasets = {\n",
    "    'base': (X_train_base, y_train, X_test_base, y_test), }\n",
    "#'cluster-feature': (X_train, y_train, X_test, y_test), \n",
    "#'cluster-0': (X_train_0, y_train_0, X_test_0, y_test_0),\n",
    "#'cluster-1': (X_train_1, y_train_1, X_test_1, y_test_1),\n",
    "#'cluster-2': (X_train_2, y_train_2, X_test_2, y_test_2),\n",
    "#'cluster-3': (X_train_3, y_train_3, X_test_3, y_test_3),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77fa1ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "User 3468    3\n",
       "User 2480    3\n",
       "User 4388    3\n",
       "User 4196    1\n",
       "User 2224    1\n",
       "Name: Clusters4, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24290604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7d41915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=800, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=800, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=800, random_state=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression(solver='lbfgs',\n",
    "                                max_iter=800,\n",
    "                                random_state=1)\n",
    "classifier.fit(X_train_base, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54299f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prediction  Actual\n",
       "0           3       3\n",
       "1           3       3\n",
       "2           3       3\n",
       "3           1       1\n",
       "4           1       1\n",
       "5           3       3\n",
       "6           0       0\n",
       "7           0       0\n",
       "8           0       0\n",
       "9           0       0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test_base)\n",
    "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55654935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9875366568914956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       309\n",
      "           1       0.99      0.99      0.99       467\n",
      "           2       0.98      0.99      0.98       255\n",
      "           3       0.99      0.98      0.99       333\n",
      "\n",
      "    accuracy                           0.99      1364\n",
      "   macro avg       0.99      0.99      0.99      1364\n",
      "weighted avg       0.99      0.99      0.99      1364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate a logistic regression model using repeated k-fold cross-validation\n",
    "\n",
    "# prepare the cross-validation procedure\n",
    "rcv = RepeatedKFold(n_splits=10, n_repeats=5, random_state=1)\n",
    "scoring = ['accuracy','precision_weighted','recall_weighted','f1_weighted']\n",
    "# create model\n",
    "model = LogisticRegression() #classifier\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X_train_base, y_train, scoring='accuracy', cv=rcv, n_jobs=-1)\n",
    "\n",
    "# report performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "# print(condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aff290ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key text.latex.preview in file C:\\Users\\bkuro\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 123 ('text.latex.preview : False')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key mathtext.fallback_to_cm in file C:\\Users\\bkuro\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 155 ('mathtext.fallback_to_cm : True  # When True, use symbols from the Computer Modern')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key savefig.jpeg_quality in file C:\\Users\\bkuro\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 418 ('savefig.jpeg_quality: 95       # when a jpeg is saved, the default quality parameter.')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key keymap.all_axes in file C:\\Users\\bkuro\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 466 ('keymap.all_axes : a                 # enable all axes')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key animation.avconv_path in file C:\\Users\\bkuro\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 477 ('animation.avconv_path: avconv     # Path to avconv binary. Without full path')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key animation.avconv_args in file C:\\Users\\bkuro\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 479 ('animation.avconv_args:            # Additional arguments to pass to avconv')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 mean=0.9831 se=0.002\n",
      ">2 mean=0.9828 se=0.002\n",
      ">3 mean=0.9830 se=0.001\n",
      ">4 mean=0.9833 se=0.001\n",
      ">5 mean=0.9833 se=0.001\n",
      ">6 mean=0.9836 se=0.001\n",
      ">7 mean=0.9834 se=0.001\n",
      ">8 mean=0.9835 se=0.001\n",
      ">9 mean=0.9836 se=0.001\n",
      ">10 mean=0.9835 se=0.001\n",
      ">11 mean=0.9835 se=0.001\n",
      ">12 mean=0.9836 se=0.001\n",
      ">13 mean=0.9836 se=0.001\n",
      ">14 mean=0.9837 se=0.001\n",
      ">15 mean=0.9837 se=0.001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# compare the number of repeats for repeated k-fold cross-validation\n",
    "from scipy.stats import sem\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# evaluate a model with a given number of repeats\n",
    "def evaluate_model(X, y, repeats):\n",
    "\t# prepare the cross-validation procedure\n",
    "\tcv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "\t# create model\n",
    "\tmodel = LogisticRegression()\n",
    "\t# evaluate model\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    " \n",
    "# load my dataset\n",
    "#X_train_base, y_train = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "# configurations to test\n",
    "repeats = range(1,16)\n",
    "results = list()\n",
    "for r in repeats:\n",
    "\t# evaluate using a given number of repeats\n",
    "\tscores = evaluate_model(X_train_base, y_train, r)\n",
    "\t# summarize\n",
    "\tprint('>%d mean=%.4f se=%.3f' % (r, mean(scores), sem(scores)))\n",
    "\t# store\n",
    "\tresults.append(scores)\n",
    "# plot the outcome\n",
    "pyplot.boxplot(results, labels=[str(r) for r in repeats], showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c164ba47",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "def run_exps(datasets: dict) -> pd.DataFrame:\n",
    "    '''\n",
    "    runs experiments on a dict of datasets\n",
    "    '''\n",
    "    # initialize a logistic regression classifier\n",
    "    model = LogisticRegression(class_weight='balanced', solver='lbfgs', random_state=997, max_iter=800)\n",
    "    \n",
    "    dfs = []\n",
    "    results = []\n",
    "    conditions = []\n",
    "    scoring = ['accuracy','precision_weighted','recall_weighted','f1_weighted']\n",
    "\n",
    "    for condition, splits in datasets.items():\n",
    "            X_train = splits[0]\n",
    "            y_train = splits[1]\n",
    "            X_test = splits[2]\n",
    "            y_test = splits[3]\n",
    "\n",
    "            kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=90210)\n",
    "            cv_results = model_selection.cross_validate(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "            clf = model.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            print(condition)\n",
    "            print(classification_report(y_test, y_pred))\n",
    "\n",
    "    results.append(cv_results)\n",
    "    conditions.append(condition)\n",
    "\n",
    "    this_df = pd.DataFrame(cv_results)\n",
    "    this_df['condition'] = condition\n",
    "    dfs.append(this_df)\n",
    "\n",
    "    final = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    # We have wide format data, lets use pd.melt to fix this\n",
    "    results_long = pd.melt(final,id_vars=['condition'],var_name='metrics', value_name='values')\n",
    "    \n",
    "    # fit time metrics, we don't need these\n",
    "    time_metrics = ['fit_time','score_time'] \n",
    "    results = results_long[~results_long['metrics'].isin(time_metrics)] # get df without fit data\n",
    "    results = results.sort_values(by='values')\n",
    "    \n",
    "    return results\n",
    "\n",
    "df = run_exps(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9872c444",
   "metadata": {},
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(20, 12))\n",
    "sns.set(font_scale=2.5)\n",
    "g = sns.boxplot(x=\"condition\", y=\"values\", hue=\"metrics\", data=df, palette=\"Set3\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title('Comparison of Dataset by Classification Metric')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3caf01",
   "metadata": {},
   "source": [
    "pd.pivot_table(df, index='condition',columns=['metrics'],values=['values'], aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601a63d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0ca66d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d3d0ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e008537",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
